{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded NEW llm_api with OpenAI SDK v1.x syntax\n",
      "✅ Environment variables loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Importing main.py functions\n",
    "from main import (\n",
    "    setup_environment,\n",
    "    process_resume,\n",
    "    split_resume_into_sections,\n",
    "    process_job_posting,\n",
    "    extract_keywords,\n",
    "    calculate_keyword_match,\n",
    "    filter_relevant_keywords,\n",
    "    enhance_section\n",
    ")\n",
    "\n",
    "from parsing_module import extract_headers_with_pdfplumber\n",
    "\n",
    "setup_environment()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HEADER CANDIDATE] 'Neal Iyer'\n",
      "[HEADER CANDIDATE] 'Professional Summary'\n",
      "[NORMALIZED] 'Professional Summary' → 'summary'\n",
      "[HEADER CANDIDATE] 'Professional Skills'\n",
      "[NORMALIZED] 'Professional Skills' → 'skills'\n",
      "[HEADER CANDIDATE] 'Workforce Planning'\n",
      "[HEADER CANDIDATE] 'Optimization'\n",
      "[HEADER CANDIDATE] 'Communication'\n",
      "[HEADER CANDIDATE] 'Proactive Problem-Solving\n",
      "Experience'\n",
      "[HEADER CANDIDATE] 'Budget Analyst'\n",
      "[HEADER CANDIDATE] 'Budget Analyst'\n",
      "[HEADER CANDIDATE] 'Cresa\n",
      "Accounting Analyst'\n",
      "[HEADER CANDIDATE] 'FrontStream\n",
      "Fund Accountant'\n",
      "[HEADER CANDIDATE] 'Education and Certifications'\n",
      "[normalize_section_name] GPT returned: 'education' for 'Education and Certifications'\n",
      "[NORMALIZED] 'Education and Certifications' → 'education'\n",
      "[HEADER CANDIDATE] 'Flatiron Data Science Bootcamp'\n",
      "[HEADER CANDIDATE] 'HackerRank Intermediate SQL Certification'\n",
      "[HEADER CANDIDATE] 'Projects'\n",
      "[FORCED-NORMALIZED] 'Projects' → 'projects' (from font size match)\n",
      "[INJECTED] Forcing section 'experience' from pdfplumber headers\n",
      "[INJECTED] Forcing section 'certifications' from pdfplumber headers\n",
      "\n",
      "[DEBUG] Headers from pdfplumber: ['Neal', 'Iyer', 'Professional', 'Summary', 'Skills', 'Experience', 'Experience', 'Education', 'and', 'Certifications', 'Projects']\n",
      "✅ Resume and job posting processed successfully.\n",
      "Found Resume Sections: ['summary', 'skills', 'education', 'projects', 'experience', 'certifications']\n"
     ]
    }
   ],
   "source": [
    "resume_file = \"docs/sample_resume.pdf\"\n",
    "job_input = \"\"\"\n",
    "[Big Data Tools Developer\n",
    "\n",
    "We build, improve, and maintain one of the highest scaling platforms in the world. Our amazing team of Engineers work on next generation Big Data Platforms that transform how users connect with each other every single day. Yahoo's Big Data Platform drives some of the most demanding applications in the industry. The system handles billions of requests a day and runs on some of the largest Hadoop clusters ever built! 50,000 nodes strong and several multi-thousand node clusters bring scalable computing to a whole new level. We work on problems that cover a wide spectrum - from web services to operating systems and networking layers. Our biggest challenges ahead are designing efficient cloud native big data platforms.\n",
    "\n",
    "Responsibilities:\n",
    "\n",
    "Job Monitoring: Overseeing the execution of various data jobs, ensuring they adhere to SLAs and do not encounter issues.\n",
    "Data Orchestration: Utilizing tools like Airflow to manage the scheduling, execution, and monitoring of data workflows across cloud platforms such as AWS and GCP.\n",
    "Query Execution and Optimization: Designing and optimizing queries to run efficiently on platforms such as BigQuery, Hive, Pig, and Spark, ensuring high performance and scalability.\n",
    "Integration and Support: Collaborating with different teams to integrate data flows, provide support for query executions, and handle credentials for secure data operations.\n",
    "Feature Development: Implementing new features to support advanced query capabilities, including federated queries and lineage tracking.\n",
    "\n",
    "Required Skills and Qualifications:\n",
    "\n",
    "Educational Background: A Bachelor's or Master’s degree in Computer Science or equivalent work experience.\n",
    "Programming Languages: Proficiency in Python is essential for scripting and workflow management; experience with Java and C++ is preferred for backend data operations.\n",
    "Data Management: Knowledge of data structures, algorithms, and database management systems like SQL, HBase, and BigQuery.\n",
    "Cloud Technologies: Experience with cloud services, especially AWS (EMR, Glue, S3) and GCP (Dataproc, BigQuery).\n",
    "Agile Methodology: Comfortable working in an Agile environment with regular sprints, planning, and retrospectives.\n",
    "System Design: Ability to design large-scale, distributed systems that are highly available and resilient.\n",
    "OS: Some experience working with Linux/Unix operating systems\n",
    "\n",
    "Preferred Qualifications:\n",
    "\n",
    "Experience with development and deployment on public cloud platforms such as AWS, GCP, Azure, or others\n",
    "Experiencing developing containerized applications and working with container orchestration services\n",
    "Experience with Apache Hadoop, Presto, Hive, Oozie, Pig, Storm, Spark, Jupyter\n",
    "Understanding of data structures & algorithms\n",
    "Knowledge of JVM internals and its performance tuning\n",
    "Excellent debugging/testing skills, and excellent analytical and problem solving skills\n",
    "Experience with continuous integration tools such as Jenkins and Hudson\n",
    "Strong verbal and written communication skills to collaborate effectively with cross-functional teams.]\n",
    "\"\"\"\n",
    "\n",
    "# Extract text from resume and job posting\n",
    "resume_text = process_resume(resume_file)\n",
    "job_text = process_job_posting(job_input)\n",
    "\n",
    "# Parse sections from resume\n",
    "sections = split_resume_into_sections(resume_text, pdf_path=resume_file)\n",
    "\n",
    "# DEBUG: Print pdfplumber headers directly\n",
    "pdf_headers = extract_headers_with_pdfplumber(resume_file)\n",
    "print(\"\\n[DEBUG] Headers from pdfplumber:\", pdf_headers)\n",
    "\n",
    "\n",
    "# Extract overall keywords\n",
    "resume_keywords = extract_keywords(resume_text)\n",
    "job_keywords = extract_keywords(job_text)\n",
    "\n",
    "print(\"✅ Resume and job posting processed successfully.\")\n",
    "print(f\"Found Resume Sections: {list(sections.keys())}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Enhancing: SUMMARY ---\n",
      "Relevant Keywords: SQL, Python, workforce analytics, reporting automation, budget forecasting, Power BI, stakeholder communication\n",
      "\n",
      "--- Enhancing: SKILLS ---\n",
      "Relevant Keywords: SQL, Python, workforce analytics, reporting automation, budget forecasting, Power BI, stakeholder communication\n",
      "\n",
      "=== ENHANCED SUMMARY ===\n",
      "\n",
      "[Improved summary section with keywords: SQL, Python, workforce analytics, reporting automation, budget forecasting, Power BI, stakeholder communication]\n",
      "\n",
      "Federal Data Analyst with 4+ years in human capital analytics, data-driven decision-making, and workforce planning. \n",
      "Skilled in SQL, Python, Tableau, and Power BI, with a track record of optimizing HR processes through data analysis, \n",
      "reporting automation, and visualization.\n",
      "\n",
      "=== ENHANCED SKILLS ===\n",
      "\n",
      "[Improved skills section with keywords: SQL, Python, workforce analytics, reporting automation, budget forecasting, Power BI, stakeholder communication]\n",
      "\n",
      "● Data Analytics & Visualization: SQL · Python · Tableau · Power BI · Advanced Excel · Advanced MS Office Suite  \n",
      "● Human Capital & Workforce Analytics: HR Metrics · Hiring Pipeline Analytics · Employee Retention Analysis\n"
     ]
    }
   ],
   "source": [
    "# === Mock GPT Function ===\n",
    "def mock_gpt_enhancement(section_name, section_text, job_keywords):\n",
    "    \"\"\"\n",
    "    Simulates GPT enhancement by inserting keywords and tagging improvement areas.\n",
    "    Replace with real OpenAI API call later.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Enhancing: {section_name.upper()} ---\")\n",
    "    print(\"Relevant Keywords:\", \", \".join(job_keywords))\n",
    "\n",
    "    # Simulated enhancement (stub)\n",
    "    enhanced = f\"[Improved {section_name} section with keywords: {', '.join(job_keywords)}]\\n\\n{section_text}\"\n",
    "    return enhanced\n",
    "\n",
    "\n",
    "# === Sample Data (Replace with your parsed_sections object) ===\n",
    "parsed_sections = {\n",
    "    \"summary\": \"\"\"\n",
    "Federal Data Analyst with 4+ years in human capital analytics, data-driven decision-making, and workforce planning. \n",
    "Skilled in SQL, Python, Tableau, and Power BI, with a track record of optimizing HR processes through data analysis, \n",
    "reporting automation, and visualization.\n",
    "\"\"\".strip(),\n",
    "\n",
    "    \"skills\": \"\"\"\n",
    "● Data Analytics & Visualization: SQL · Python · Tableau · Power BI · Advanced Excel · Advanced MS Office Suite  \n",
    "● Human Capital & Workforce Analytics: HR Metrics · Hiring Pipeline Analytics · Employee Retention Analysis\n",
    "\"\"\".strip()\n",
    "}\n",
    "\n",
    "# === Sample Keywords ===\n",
    "job_keywords = [\n",
    "    \"SQL\", \"Python\", \"workforce analytics\", \"reporting automation\", \n",
    "    \"budget forecasting\", \"Power BI\", \"stakeholder communication\"\n",
    "]\n",
    "\n",
    "# === Extract Text from Parsed Sections ===\n",
    "summary_text = parsed_sections.get(\"summary\", \"\")\n",
    "skills_text = parsed_sections.get(\"skills\", \"\")\n",
    "\n",
    "# === Enhance Sections ===\n",
    "enhanced_summary = mock_gpt_enhancement(\"summary\", summary_text, job_keywords)\n",
    "enhanced_skills = mock_gpt_enhancement(\"skills\", skills_text, job_keywords)\n",
    "\n",
    "# === Print Results ===\n",
    "print(\"\\n=== ENHANCED SUMMARY ===\\n\")\n",
    "print(enhanced_summary)\n",
    "\n",
    "print(\"\\n=== ENHANCED SKILLS ===\\n\")\n",
    "print(enhanced_skills)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== REAL ENHANCED SUMMARY ===\n",
      "\n",
      "SUMMARY\n",
      "\n",
      "Highly accomplished Federal Data Analyst offering over four years of experience in the realm of human capital analytics, data-driven decision-making, and strategic workforce planning. Proficient in leveraging SQL and Python in conjunction with visualization tools like Tableau and Power BI to enhance workforce analytics. Demonstrated expertise in reporting automation, budget forecasting, and stakeholder communication, leading to optimized HR processes and informed decision-making.\n",
      "\n",
      "=== REAL ENHANCED SKILLS ===\n",
      "\n",
      "● Data Analytics & Visualization: Proficient in SQL and Python for data analysis and manipulation. Expertise in creating interactive dashboards and visualizations using Tableau and Power BI. Highly skilled in Advanced Excel and MS Office Suite.\n",
      "● Workforce Analytics: Adept at utilizing HR metrics in workforce analytics to build comprehensive hiring pipeline analytics and employee retention analysis. Skilled in reporting automation, budget forecasting, and stakeholder communication for effective decision-making.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# === Step 1: Define GPT-enhancement function ===\n",
    "def enhance_section_with_gpt(section_name, section_text, job_keywords, client=None, model=\"gpt-4\"):\n",
    "    \"\"\"\n",
    "    Uses GPT to rewrite a resume section (summary or skills).\n",
    "    \"\"\"\n",
    "    if client is None:\n",
    "        raise ValueError(\"OpenAI client must be provided.\")\n",
    "\n",
    "    prompt = (\n",
    "        \"You are an expert resume writer.\\n\\n\"\n",
    "        \"Improve the following resume section for clarity, tone, and professionalism.\\n\"\n",
    "        \"Preserve any bullet formatting if it exists.\\n\\n\"\n",
    "        f\"Integrate the following job-relevant keywords naturally and only where appropriate:\\n\"\n",
    "        f\"{', '.join(job_keywords)}\\n\\n\"\n",
    "        f\"Section to improve: {section_name.upper()}\\n\\n\"\n",
    "        f\"```\\n{section_text}\\n```\\n\\n\"\n",
    "        \"Respond only with the improved section text.\"\n",
    "    )\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.7\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "\n",
    "# === Step 2: Sample data ===\n",
    "summary_text = \"\"\"\n",
    "Federal Data Analyst with 4+ years in human capital analytics, data-driven decision-making, and workforce planning. \n",
    "Skilled in SQL, Python, Tableau, and Power BI, with a track record of optimizing HR processes through data analysis, \n",
    "reporting automation, and visualization.\n",
    "\"\"\".strip()\n",
    "\n",
    "skills_text = \"\"\"\n",
    "● Data Analytics & Visualization: SQL · Python · Tableau · Power BI · Advanced Excel · Advanced MS Office Suite  \n",
    "● Human Capital & Workforce Analytics: HR Metrics · Hiring Pipeline Analytics · Employee Retention Analysis\n",
    "\"\"\".strip()\n",
    "\n",
    "job_keywords = [\n",
    "    \"SQL\", \"Python\", \"workforce analytics\", \"reporting automation\", \n",
    "    \"budget forecasting\", \"Power BI\", \"stakeholder communication\"\n",
    "]\n",
    "\n",
    "\n",
    "# === Step 3: Enhance sections using GPT ===\n",
    "real_summary = enhance_section_with_gpt(\"summary\", summary_text, job_keywords, client=client)\n",
    "real_skills = enhance_section_with_gpt(\"skills\", skills_text, job_keywords, client=client)\n",
    "\n",
    "# === Step 4: Output results ===\n",
    "print(\"\\n=== REAL ENHANCED SUMMARY ===\\n\")\n",
    "print(real_summary)\n",
    "\n",
    "print(\"\\n=== REAL ENHANCED SKILLS ===\\n\")\n",
    "print(real_skills)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
