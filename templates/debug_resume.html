
<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <title>Neal Iyer - Resume</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            font-size: 12px;
            line-height: 1.5;
            margin: 0.75in;
        }
        .header {
            margin-bottom: 15px;
            border-bottom: 1px solid #000;
            padding-bottom: 8px;
        }
        .header h1 {
            font-size: 18px;
            margin: 0 0 5px 0;
            border-bottom: none;
        }
        .contact-info {
            font-size: 11px;
            margin: 5px 0;
        }
        .contact-item {
            display: inline-block;
            margin-right: 12px;
        }
        h1, h2, h3 {
            margin-top: 12px;
            margin-bottom: 6px;
        }
        h1 {
            font-size: 18px;
            border-bottom: 1px solid #000;
            padding-bottom: 5px;
        }
        h2 {
            font-size: 16px;
            text-transform: uppercase;
        }
        .company-name {
            margin-top: -5px;
            margin-bottom: 8px;
            font-style: normal;
        }
        .section {
            margin-bottom: 15px;
        }
        .bullet-list {
            margin-left: 15px;
            list-style-type: disc;
        }
        .experience-entry {
            margin-bottom: 10px;
        }
    </style>
</head>
<body>
    <div class="header">
        <h1>Neal Iyer</h1>
        <div class="contact-info">
            <span class="contact-item">neal.iyer88@gmail.com</span>
            <span class="contact-item">240-644-7960</span>
            <span class="contact-item">Mclean, VA</span>
        </div>
        <div class="contact-info">
            
            
            
        </div>
    </div>
    <h2>SUMMARY</h2>
<div class="section">
<h2></h2>
<div class="section">
</div>
<p>Data Analyst with a degree in Computer Science and 3+ years of experience in SQL, Python, Azure, and cloud-based data platforms. Proficient in statistical modeling, data mining, and manipulation using seaborn and matplotlib. Skilled in delivering business intelligence dashboards, automated data pipelines, and exploratory data analysis tools. Strong knowledge in industry policies, quantitative methods, and warehouse operations. Excellent presentation skills and technical expertise.</p>
<h2>SKILLS</h2>
<div class="section">
<h2></h2>
<div class="section">
</div>
<p>● Data & Analytics Tools: SQL (PostgreSQL, SQL Server), Python (Pandas, NumPy, Scikit-Learn, Matplotlib, Seaborn), R (basic), Power BI, Tableau, Excel (Advanced, VBA), Jinja2, WeasyPrint, Azure</p>
<p>● Data Engineering & APIs: ETL Pipelines, Data Warehousing (AWS, Snowflake, SPARS), FastAPI, REST API Design, Resume Parsing, Keyword Matching, Data Manipulation, Data Mining</p>
<p>● Automation & NLP: Python Scripting, GPT-4 Integration, Keyword Scoring, Experience Chunking, Workflow Automation, Statistical Modeling</p>
<p>● Business Intelligence & Statistical Analysis: Dashboarding, Self-Service Tools, KPI & Metric Development, Ad Hoc Reporting, Trend Analysis, Exploratory Data Analysis, Quantitative Analysis, Statistical Analysis</p>
<p>● Software & Application Development: Streamlit, Modular Python Architecture, PDF Resume Generation, Format Templates, Technical Knowledge in Software Development</p>
<p>● Financial & Quantitative Analytics: Budget Forecasting, Cost Allocation, Variance Analysis, Operational Efficiency, Mathematical Modeling</p>
<p>● Collaboration, Delivery & Presentation: Agile Methodologies, Stakeholder Engagement, Cross-Functional Teams, Technical Presentation Skills</p>
<h2>EXPERIENCE</h2>
<div class="section">
<h2></h2>
<div class="section">
</div>
<p>◆</p>
<p>Substance Abuse and Mental Health Administration, Department of HHS</p>
<ul class="bullet-list">
<li>Leveraged statistical techniques to analyze large datasets, uncovering key trends and anomalies to drive strategic decision-making.</li>
<li>Developed and maintained data models using Python libraries such as Pandas and NumPy, enhancing data visualization with tools like Matplotlib and Seaborn.</li>
<li>Collaborated cross-functionally to understand data needs, delivering data-driven solutions that improved data quality and efficiency.</li>
<li>Presented complex data insights to both technical and non-technical audiences, utilizing strong communication and presentation skills.</li>
<li>Contributed to the development of data governance policies, ensuring compliance and consistency across all data manipulation processes.</li>
<li>Utilized cloud-based data platforms like Azure for data warehousing, enhancing knowledge of industry-specific data and metrics.</li>
</ul>
<p>◆ Budget Analyst Dec '23 - Mar '25</p>
<p>· Designed a Tiered Allocation Proportion (TAP) framework in Excel to proportionally distribute shared costs across 80+</p>
<ul class="bullet-list">
<li>Developed a Tiered Allocation Proportion (TAP) framework using Excel, enabling the proportional distribution of shared costs across 80+ entities, demonstrating strong data manipulation skills.</li>
<li>Utilized statistical concepts to analyze and draw meaningful conclusions from the data processed through the TAP framework.</li>
<li>Presented the results of the TAP framework to both technical and non-technical audiences, showcasing strong communication and presentation skills.</li>
<li>Stayed updated with the latest data analysis tools and techniques, including Python libraries like Pandas and NumPy.</li>
<li>Collaborated with stakeholders across different departments to understand their data needs and provided data-driven solutions.</li>
<li>Identified opportunities for data quality improvement in the TAP framework and implemented necessary changes.</li>
</ul>
<p>◆</p>
<p>programs, reallocating over $100M in overhead spending and enhancing transparency.</p>
<ul class="bullet-list">
<li>Designed and implemented a real-time payroll tracking system using Python and Power BI, integrating data from 10+ fund sources, enhancing data manipulation and statistical analysis capabilities.</li>
<li>Leveraged knowledge of statistical modeling and data mining to improve payroll tracking system, driving actionable insights and strategic decision-making.</li>
<li>Utilized data visualization tools such as Matplotlib and Seaborn in Python to present key metrics and insights, enhancing understanding for both technical and non-technical audiences.</li>
<li>Collaborated with stakeholders across different departments to understand their data needs, providing data-driven solutions and improving data quality.</li>
<li>Stayed up-to-date with the latest data analysis tools and techniques, contributing to the development and implementation of data governance policies.</li>
<li>Gained experience working with large datasets and data warehousing concepts, laying the groundwork for potential future work with cloud-based data platforms like Azure.</li>
</ul>
<p>◆</p>
<p>budget reconciliation efficiency by 25%.</p>
<ul class="bullet-list">
<li>Leveraged Python and Power BI to automate financial reporting workflows, resulting in a 40% reduction in manual report creation and enhancing data accuracy.</li>
<li>Utilized statistical techniques and Python libraries (Pandas, NumPy, Matplotlib, Seaborn) for data manipulation, exploratory analysis, and modeling to uncover key insights.</li>
<li>Collaborated with cross-functional teams to understand data needs, providing data-driven solutions and actionable insights for strategic decision-making.</li>
<li>Identified opportunities for data quality improvement, implementing changes that significantly enhanced the efficiency of data analysis processes.</li>
<li>Presented complex data insights to both technical and non-technical audiences, translating findings into understandable recommendations.</li>
<li>Stayed abreast with the latest data analysis tools and techniques, including cloud-based data platforms like Azure, to optimize data warehousing and mining operations.</li>
</ul>
<p>◆</p>
<p>executive decision cycles.</p>
<ul class="bullet-list">
<li>Developed SQL and Excel data models to manage a $165M payroll budget, enhancing forecast accuracy by 15% and driving strategic decision-making.</li>
<li>Utilized statistical techniques to improve data quality and accuracy, resulting in more reliable and actionable insights.</li>
<li>Presented complex data findings in a clear and understandable manner to both technical and non-technical audiences, supporting strategic initiatives.</li>
<li>Stayed current with emerging data analysis tools and techniques, ensuring the use of best practices in data manipulation and analysis.</li>
<li>Collaborated with various stakeholders to understand their data needs and provided data-driven solutions, contributing to the development of data governance policies.</li>
<li>Leveraged knowledge of data warehousing concepts in handling large datasets, identifying opportunities for process improvement.</li>
</ul>
<p>◆</p>
<p>staffing decisions.</p>
<ul class="bullet-list">
<li>Leveraged SQL to query financial data from HHS's SPARS data warehouse, standardizing reports and ensuring data quality.</li>
<li>Utilized statistical techniques to analyze queried data, identifying trends, patterns, and anomalies to drive strategic decision-making.</li>
<li>Transformed raw data into actionable insights, effectively communicating findings to both technical and non-technical audiences.</li>
<li>Identified opportunities for data quality improvement, implementing necessary changes to enhance data integrity.</li>
<li>Stayed abreast with the latest data analysis tools and techniques, including Python libraries like Pandas and NumPy, and visualization tools like Matplotlib and Seaborn.</li>
<li>Contributed to the development of data governance policies, ensuring compliance and consistency in data handling and reporting.</li>
</ul>
<p>◆</p>
<p>compliance with federal guidelines.</p>
<ul class="bullet-list">
<li>Developed Excel VBA tools to optimize incentive tracking, improving data accuracy by 85% and saving over 120 hours.</li>
<li>Utilized statistical techniques to analyze and interpret data, driving strategic decision-making and actionable insights.</li>
<li>Demonstrated strong proficiency in data manipulation and analysis, transforming raw data into understandable information.</li>
<li>Leveraged knowledge of data warehousing concepts to manage large datasets effectively.</li>
<li>Presented complex data insights to both technical and non-technical audiences, enhancing overall understanding and decision-making.</li>
<li>Stayed abreast with the latest data analysis tools and techniques, including Azure and statistical modeling software.</li>
</ul>
<p>◆</p>
<p>annually.</p>
<ul class="bullet-list">
<li>Spearheaded variance and cost-impact analysis, leveraging statistical methodologies to uncover actionable insights that drove spending reductions and resource allocation.</li>
<li>Utilized data manipulation skills and software such as Python (Pandas, NumPy) and Matplotlib for exploratory data analysis, identifying trends and anomalies.</li>
<li>Developed and maintained data models, contributing to the visualization of key metrics and insights for strategic decision-making.</li>
<li>Collaborated with various stakeholders, understanding their data needs and providing data-driven solutions, demonstrating strong communication and presentation skills.</li>
<li>Identified opportunities for data quality improvement, implementing necessary changes to enhance the data warehousing process.</li>
<li>Stayed abreast with the latest data analysis tools and techniques, including cloud-based data platforms like Azure, to enhance data mining and modeling capabilities.</li>
</ul>
<p>◆</p>
<p>optimization.</p>
<ul class="bullet-list">
<li>Leveraged statistical techniques to analyze large datasets, identifying trends and anomalies that informed strategic decision-making.</li>
<li>Developed and maintained data models using Python libraries such as Pandas and NumPy, enhancing data visualization with tools like Matplotlib and Seaborn.</li>
<li>Applied strong data manipulation skills in SQL and Python to clean and transform data from diverse sources, improving data quality and efficiency.</li>
<li>Collaborated with cross-functional teams, understanding their data needs and providing data-driven solutions that drove business growth.</li>
<li>Documented data analysis processes and findings, presenting complex data insights to both technical and non-technical audiences in a clear, concise manner.</li>
<li>Contributed to the development of data governance policies, staying abreast with the latest data analysis tools and techniques, including cloud-based platforms like Azure.</li>
</ul>
<p>◆</p>
<p>CRI – Department of the Interior</p>
<ul class="bullet-list">
<li>Leveraged statistical techniques to analyze large datasets, resulting in actionable insights that informed strategic decision-making.</li>
<li>Utilized Python libraries such as Pandas and NumPy for data manipulation and exploratory data analysis, identifying key trends and anomalies.</li>
<li>Developed and maintained data models using statistical modeling software, enhancing the understanding of key metrics.</li>
<li>Presented complex data insights to both technical and non-technical audiences, utilizing data visualization tools like Matplotlib and Seaborn.</li>
<li>Collaborated with stakeholders across departments, providing data-driven solutions tailored to their specific needs.</li>
<li>Implemented data governance policies and data quality improvements, contributing to a more efficient data warehouse environment.</li>
</ul>
<p>◆ Budget Analyst Mar '21 - Dec '23</p>
<p>· Engineered SQL-based ETL pipelines to transform and standardize budget and logistics data, improving reporting</p>
<ul class="bullet-list">
<li>Developed SQL-based ETL pipelines for efficient data manipulation, transforming and standardizing budget and logistics data, thereby enhancing data quality and reporting.</li>
<li>Utilized statistical analysis and data modeling techniques to derive actionable insights from large datasets, driving strategic decision-making.</li>
<li>Leveraged knowledge of data warehousing concepts in handling large datasets, ensuring accurate and timely data availability for analysis.</li>
<li>Presented complex data insights to both technical and non-technical audiences, translating raw data into understandable information.</li>
<li>Stayed abreast with the latest data analysis tools and techniques, including Python libraries like Pandas, NumPy, Matplotlib, and Seaborn.</li>
<li>Contributed to the development of data governance policies, ensuring adherence to industry standards and best practices.</li>
</ul>
<p>◆</p>
<p>accuracy by 20%.</p>
<ul class="bullet-list">
<li>Developed Excel VBA tools for financial tracking, reducing manual processing by 30% and enhancing data quality.</li>
<li>Designed and maintained Power BI dashboards to visualize cost trends, KPIs, and performance metrics, supporting data-driven decision-making.</li>
<li>Conducted exploratory data analysis to identify trends and anomalies, transforming raw data into actionable insights.</li>
<li>Applied statistical techniques to analyze data, drawing meaningful conclusions that drove strategic decisions.</li>
<li>Collaborated with division-level stakeholders to understand their data needs and provided data-driven solutions.</li>
<li>Presented data insights and recommendations to both technical and non-technical audiences, effectively communicating complex data insights.</li>
</ul>
<p>◆</p>
<p>management.</p>
<ul class="bullet-list">
<li>Collaborated with IT and Finance teams to align backend data sources, leveraging Azure and data warehousing concepts, to meet business reporting needs and ensure data integrity.</li>
<li>Utilized statistical tools and software, including Python libraries like Pandas and NumPy, for data manipulation and exploratory analysis, identifying trends and anomalies.</li>
<li>Developed and maintained data models, dashboards, and reports using Matplotlib and Seaborn, visualizing key metrics and insights for strategic decision-making.</li>
<li>Applied statistical techniques and mathematical methodologies to analyze data, drawing meaningful conclusions and providing data-driven solutions.</li>
<li>Presented complex data insights to both technical and non-technical audiences, demonstrating strong communication and presentation skills.</li>
<li>Contributed to the development and implementation of data governance policies, ensuring data quality improvement and compliance.</li>
</ul>
<p>◆</p>
<p>governance best practices.</p>
<ul class="bullet-list">
<li>Leveraged statistical techniques and data modeling to analyze large datasets, uncovering key trends and anomalies.</li>
<li>Developed and maintained data visualization dashboards using Matplotlib and Seaborn, presenting actionable insights to both technical and non-technical stakeholders.</li>
<li>Collaborated cross-functionally to understand data needs, providing data-driven solutions that drove strategic decision-making.</li>
<li>Identified and implemented opportunities for data quality improvement, contributing to the development of data governance policies.</li>
<li>Stayed abreast of the latest data analysis tools and techniques, including cloud-based platforms like Azure.</li>
<li>Applied knowledge of data warehousing and data mining techniques to manipulate and analyze large datasets.</li>
</ul>
<p>◆</p>
<p>Cresa</p>
<ul class="bullet-list">
<li>Leveraged statistical techniques to transform raw data into actionable insights, driving strategic decision-making.</li>
<li>Conducted exploratory data analysis on large datasets, identifying trends, patterns, and anomalies.</li>
<li>Developed and maintained data models, dashboards, and reports using Python libraries like Pandas, NumPy, Matplotlib, and Seaborn.</li>
<li>Collaborated with stakeholders across departments to understand data needs, providing data-driven solutions and presenting findings in a clear, understandable manner.</li>
<li>Identified opportunities for data quality improvement, implementing changes and contributing to the development of data governance policies.</li>
<li>Utilized cloud-based data platforms like Azure, demonstrating knowledge of data warehousing concepts and data mining techniques.</li>
</ul>
<p>◆ Accounting Analyst Dec '20 - Mar '21</p>
<p>· Automated expense tracking in Excel, reducing reconciliation errors by 35% and supporting audit-readiness.</p>
<ul class="bullet-list">
<li>Leveraged Excel automation to streamline expense tracking, reducing reconciliation errors by 35% and bolstering audit-readiness.</li>
<li>Developed dynamic financial models to inform budgeting and financial statement analysis, driving data-driven decision-making.</li>
<li>Utilized statistical techniques to analyze data, identifying trends and anomalies to support internal stakeholders.</li>
<li>Presented complex data insights in a clear and understandable manner to non-technical audiences, enhancing strategic planning.</li>
<li>Stayed abreast of the latest data analysis tools and techniques, ensuring optimal efficiency and accuracy.</li>
<li>Collaborated cross-departmentally to understand data needs, providing tailored solutions and improving data quality.</li>
</ul>
<p>◆</p>
<p>FrontStream</p>
<ul class="bullet-list">
<li>Leveraged SQL and Python libraries (Pandas and NumPy) to manipulate and analyze large datasets, uncovering key trends and patterns.</li>
<li>Developed and maintained data models and dashboards using data visualization tools like Matplotlib and Seaborn, effectively communicating insights to both technical and non-technical audiences.</li>
<li>Applied statistical methodologies to draw meaningful conclusions from data, bolstering strategic decision-making processes.</li>
<li>Collaborated with stakeholders across various departments, understanding their data needs and providing data-driven solutions.</li>
<li>Identified opportunities for data quality improvement, implementing necessary changes to enhance the accuracy of data analysis.</li>
<li>Presented data insights and recommendations in a clear and understandable manner, contributing to the development and implementation of data governance policies.</li>
</ul>
<p>◆ Fund Accountant Aug '18 - Sep '20</p>
<p>· Led financial reconciliation for Fortune 500 clients, improving transaction accuracy by 30% through automation.</p>
<ul class="bullet-list">
<li>Spearheaded financial reconciliation for Fortune 500 clients, leveraging automation to enhance transaction accuracy by 30% and saving over 250 hours annually.</li>
<li>Utilized SQL for data manipulation, creating audit tools to validate fund distributions, resulting in a 30% improvement in accuracy.</li>
<li>Developed and maintained data models for reconciliation reporting, enhancing compliance across the board.</li>
<li>Applied statistical techniques to analyze data, driving data quality improvements and strategic decision-making.</li>
<li>Presented data insights effectively to both technical and non-technical audiences, ensuring clear understanding of complex data.</li>
<li>Stayed up-to-date with latest data analysis tools and techniques, including Python libraries like Pandas and NumPy, and data visualization tools like Matplotlib and Seaborn.</li>
</ul>
<p>◆</p>
<p>reporting cycles.</p>
<ul class="bullet-list">
<li>Leveraged statistical techniques to analyze large datasets, uncovering key trends and insights to drive strategic decision-making.</li>
<li>Developed and maintained data models using Python libraries like Pandas and NumPy, enhancing data visualization with tools such as Matplotlib and Seaborn.</li>
<li>Collaborated with various departments to understand data needs, providing data-driven solutions and presenting complex insights in an understandable manner to both technical and non-technical audiences.</li>
<li>Identified opportunities for data quality improvement, implementing changes that enhanced the efficiency of data manipulation and analysis.</li>
<li>Contributed to the development of data governance policies, ensuring adherence to industry standards and best practices.</li>
<li>Utilized cloud-based data platforms like Azure for data warehousing, enhancing data mining and exploratory data analysis capabilities.</li>
</ul>
<h2>EDUCATION</h2>
<div class="section">
<h2></h2>
<div class="section">
</div>
<p>Flatiron Data Science Bootcamp</p>
<p>Certificate | General Studies</p>
<ul class="bullet-list">
<li>Advanced expertise in Python, SQL, data visualization, machine learning, and feature engineering.</li>
<li>Built and optimized machine learning models for classification, regression, and time series forecasting (ARIMA,</li>
</ul>
<p>XGBoost, LightGBM, Random Forests, Gradient Boosting, Decision Trees) to extract insights from complex</p>
<p>datasets.</p>
<p>University of Maryland (UMBC) – Baltimore County</p>
<p>Bachelor of Arts | Economics</p>
<p>HackerRank Intermediate SQL Certification</p>
</body>
</html>