{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded NEW llm_api with OpenAI SDK v1.x syntax\n",
      "✅ Environment variables loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Importing main.py functions\n",
    "from Rough.main import (\n",
    "    setup_environment,\n",
    "    process_resume,\n",
    "    split_resume_into_sections,\n",
    "    process_job_posting,\n",
    "    extract_keywords,\n",
    "    calculate_keyword_match,\n",
    "    filter_relevant_keywords,\n",
    "    enhance_section\n",
    ")\n",
    "\n",
    "from parsing_module import extract_headers_with_pdfplumber\n",
    "\n",
    "setup_environment()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fallback] No 'education' section found. Trying raw text extraction for education section...\n",
      "[Fallback] No 'skills' section found. Trying raw text extraction for skills section...\n",
      "[Fallback] No 'certifications' section found. Trying raw text extraction for certifications section...\n",
      "[Fallback] No 'experience' section found. Trying raw text extraction for experience section...\n",
      "[Fallback] No 'projects' section found. Trying raw text extraction for projects section...\n",
      "\n",
      "[DEBUG] Headers from pdfplumber: ['Neal', 'Iyer', 'Professional', 'Summary', 'Skills', 'Experience', 'Experience', 'Education', 'and', 'Certifications', 'Projects']\n",
      "✅ Resume and job posting processed successfully.\n",
      "Found Resume Sections: ['summary', 'education', 'skills', 'certifications', 'experience', 'projects']\n"
     ]
    }
   ],
   "source": [
    "resume_file = \"docs/sample_resume.pdf\"\n",
    "job_input = \"\"\"\n",
    "[Big Data Tools Developer\n",
    "\n",
    "We build, improve, and maintain one of the highest scaling platforms in the world. Our amazing team of Engineers work on next generation Big Data Platforms that transform how users connect with each other every single day. Yahoo's Big Data Platform drives some of the most demanding applications in the industry. The system handles billions of requests a day and runs on some of the largest Hadoop clusters ever built! 50,000 nodes strong and several multi-thousand node clusters bring scalable computing to a whole new level. We work on problems that cover a wide spectrum - from web services to operating systems and networking layers. Our biggest challenges ahead are designing efficient cloud native big data platforms.\n",
    "\n",
    "Responsibilities:\n",
    "\n",
    "Job Monitoring: Overseeing the execution of various data jobs, ensuring they adhere to SLAs and do not encounter issues.\n",
    "Data Orchestration: Utilizing tools like Airflow to manage the scheduling, execution, and monitoring of data workflows across cloud platforms such as AWS and GCP.\n",
    "Query Execution and Optimization: Designing and optimizing queries to run efficiently on platforms such as BigQuery, Hive, Pig, and Spark, ensuring high performance and scalability.\n",
    "Integration and Support: Collaborating with different teams to integrate data flows, provide support for query executions, and handle credentials for secure data operations.\n",
    "Feature Development: Implementing new features to support advanced query capabilities, including federated queries and lineage tracking.\n",
    "\n",
    "Required Skills and Qualifications:\n",
    "\n",
    "Educational Background: A Bachelor's or Master’s degree in Computer Science or equivalent work experience.\n",
    "Programming Languages: Proficiency in Python is essential for scripting and workflow management; experience with Java and C++ is preferred for backend data operations.\n",
    "Data Management: Knowledge of data structures, algorithms, and database management systems like SQL, HBase, and BigQuery.\n",
    "Cloud Technologies: Experience with cloud services, especially AWS (EMR, Glue, S3) and GCP (Dataproc, BigQuery).\n",
    "Agile Methodology: Comfortable working in an Agile environment with regular sprints, planning, and retrospectives.\n",
    "System Design: Ability to design large-scale, distributed systems that are highly available and resilient.\n",
    "OS: Some experience working with Linux/Unix operating systems\n",
    "\n",
    "Preferred Qualifications:\n",
    "\n",
    "Experience with development and deployment on public cloud platforms such as AWS, GCP, Azure, or others\n",
    "Experiencing developing containerized applications and working with container orchestration services\n",
    "Experience with Apache Hadoop, Presto, Hive, Oozie, Pig, Storm, Spark, Jupyter\n",
    "Understanding of data structures & algorithms\n",
    "Knowledge of JVM internals and its performance tuning\n",
    "Excellent debugging/testing skills, and excellent analytical and problem solving skills\n",
    "Experience with continuous integration tools such as Jenkins and Hudson\n",
    "Strong verbal and written communication skills to collaborate effectively with cross-functional teams.]\n",
    "\"\"\"\n",
    "\n",
    "# Extract text from resume and job posting\n",
    "resume_text = process_resume(resume_file)\n",
    "job_text = process_job_posting(job_input)\n",
    "\n",
    "# Parse sections from resume\n",
    "sections = split_resume_into_sections(resume_text, pdf_path=resume_file)\n",
    "\n",
    "# DEBUG: Print pdfplumber headers directly\n",
    "pdf_headers = extract_headers_with_pdfplumber(resume_file)\n",
    "print(\"\\n[DEBUG] Headers from pdfplumber:\", pdf_headers)\n",
    "\n",
    "\n",
    "# Extract overall keywords\n",
    "resume_keywords = extract_keywords(resume_text)\n",
    "job_keywords = extract_keywords(job_text)\n",
    "\n",
    "print(\"✅ Resume and job posting processed successfully.\")\n",
    "print(f\"Found Resume Sections: {list(sections.keys())}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Enhancing: SUMMARY ---\n",
      "Relevant Keywords: SQL, Python, workforce analytics, reporting automation, budget forecasting, Power BI, stakeholder communication\n",
      "\n",
      "--- Enhancing: SKILLS ---\n",
      "Relevant Keywords: SQL, Python, workforce analytics, reporting automation, budget forecasting, Power BI, stakeholder communication\n",
      "\n",
      "=== ENHANCED SUMMARY ===\n",
      "\n",
      "[Improved summary section with keywords: SQL, Python, workforce analytics, reporting automation, budget forecasting, Power BI, stakeholder communication]\n",
      "\n",
      "Federal Data Analyst with 4+ years in human capital analytics, data-driven decision-making, and workforce planning. \n",
      "Skilled in SQL, Python, Tableau, and Power BI, with a track record of optimizing HR processes through data analysis, \n",
      "reporting automation, and visualization.\n",
      "\n",
      "=== ENHANCED SKILLS ===\n",
      "\n",
      "[Improved skills section with keywords: SQL, Python, workforce analytics, reporting automation, budget forecasting, Power BI, stakeholder communication]\n",
      "\n",
      "● Data Analytics & Visualization: SQL · Python · Tableau · Power BI · Advanced Excel · Advanced MS Office Suite  \n",
      "● Human Capital & Workforce Analytics: HR Metrics · Hiring Pipeline Analytics · Employee Retention Analysis\n"
     ]
    }
   ],
   "source": [
    "# === Mock GPT Function ===\n",
    "def mock_gpt_enhancement(section_name, section_text, job_keywords):\n",
    "    \"\"\"\n",
    "    Simulates GPT enhancement by inserting keywords and tagging improvement areas.\n",
    "    Replace with real OpenAI API call later.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Enhancing: {section_name.upper()} ---\")\n",
    "    print(\"Relevant Keywords:\", \", \".join(job_keywords))\n",
    "\n",
    "    # Simulated enhancement (stub)\n",
    "    enhanced = f\"[Improved {section_name} section with keywords: {', '.join(job_keywords)}]\\n\\n{section_text}\"\n",
    "    return enhanced\n",
    "\n",
    "\n",
    "# === Sample Data (Replace with your parsed_sections object) ===\n",
    "parsed_sections = {\n",
    "    \"summary\": \"\"\"\n",
    "Federal Data Analyst with 4+ years in human capital analytics, data-driven decision-making, and workforce planning. \n",
    "Skilled in SQL, Python, Tableau, and Power BI, with a track record of optimizing HR processes through data analysis, \n",
    "reporting automation, and visualization.\n",
    "\"\"\".strip(),\n",
    "\n",
    "    \"skills\": \"\"\"\n",
    "● Data Analytics & Visualization: SQL · Python · Tableau · Power BI · Advanced Excel · Advanced MS Office Suite  \n",
    "● Human Capital & Workforce Analytics: HR Metrics · Hiring Pipeline Analytics · Employee Retention Analysis\n",
    "\"\"\".strip()\n",
    "}\n",
    "\n",
    "# === Sample Keywords ===\n",
    "job_keywords = [\n",
    "    \"SQL\", \"Python\", \"workforce analytics\", \"reporting automation\", \n",
    "    \"budget forecasting\", \"Power BI\", \"stakeholder communication\"\n",
    "]\n",
    "\n",
    "# === Extract Text from Parsed Sections ===\n",
    "summary_text = parsed_sections.get(\"summary\", \"\")\n",
    "skills_text = parsed_sections.get(\"skills\", \"\")\n",
    "\n",
    "# === Enhance Sections ===\n",
    "enhanced_summary = mock_gpt_enhancement(\"summary\", summary_text, job_keywords)\n",
    "enhanced_skills = mock_gpt_enhancement(\"skills\", skills_text, job_keywords)\n",
    "\n",
    "# === Print Results ===\n",
    "print(\"\\n=== ENHANCED SUMMARY ===\\n\")\n",
    "print(enhanced_summary)\n",
    "\n",
    "print(\"\\n=== ENHANCED SKILLS ===\\n\")\n",
    "print(enhanced_skills)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[✔] Extracted experience section from raw text.\n",
      "\n",
      "=== Experience Preview ===\n",
      "Substance Abuse and Mental Health Administration, Department of HHS\n",
      "Budget Analyst Dec '23 - Mar '25\n",
      "· Conducted data mining of critical human capital information across divisions to support strategic decision-making and\n",
      "hiring status evaluations, assessing effectiveness through comprehensive data analysis procedures to enhance workforce\n",
      "planning.\n",
      "· Developed an Excel VBA-based incentive tracking system, integrating engagement analysis and survey design to assess\n",
      "incentive award effectiveness. Implemented automated validation checks and dynamic data processing workflows,\n",
      "increasing data accuracy by 85% and enhancing communication-engagement data insights for decision-making.\n",
      "· Engineered a real-time Python-based payroll tracking system, integrating 10+ fund sources and 25 Lines of Accounting,\n",
      "leveraging SQL for data extraction and pandas for analysis, reducing reconciliation time by ~2 hours/month and\n",
      "improving payroll forecasting accuracy.\n",
      "· Designed and optimized SharePoint-based dat\n",
      "\n",
      "=== REAL ENHANCED SUMMARY ===\n",
      "\n",
      "SUMMARY\n",
      "\n",
      "Seasoned Federal Data Analyst boasting over four years of experience in the realm of human capital analytics, workforce planning, and applying data-driven strategies for decision-making. Proficient in leveraging SQL and Python for data manipulation, accompanied by detailed visualization through Tableau and Power BI. Demonstrated expertise in enhancing HR processes via comprehensive workforce analytics, efficient reporting automation, and dynamic visualization techniques. Proven ability in budget forecasting and maintaining effective stakeholder communication to drive strategic initiatives.\n",
      "\n",
      "=== REAL ENHANCED SKILLS ===\n",
      "\n",
      "● Proficient in Data Analytics and Visualization: Demonstrated expertise in SQL and Python programming, as well as advanced experience with Tableau, Power BI, and Advanced Excel for insightful data representation and analytics.\n",
      "● Skilled in Workforce Analytics: Strong understanding of Human Capital Management, adept at leveraging HR Metrics for workforce analytics including hiring pipeline analytics and employee retention analysis.\n",
      "● Budget Forecasting and Reporting Automation: Proven ability in using advanced MS Office Suite for accurate budget forecasting and efficient reporting automation.\n",
      "● Effective Stakeholder Communication: Exceptional communication skills to engage and manage stakeholder expectations effectively.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import pdfplumber\n",
    "\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# Step 0: Raw resume text directly from PDF\n",
    "pdf_path = \"docs/sample_resume.pdf\"\n",
    "with pdfplumber.open(pdf_path) as pdf:\n",
    "    full_resume_text = \"\\n\".join(page.extract_text() for page in pdf.pages if page.extract_text())\n",
    "\n",
    "# Step 1: Naive keyword search for experience block\n",
    "import re\n",
    "\n",
    "experience_match = re.search(r\"(experience|work history|employment|professional experience)(.*?)((education|projects|certifications|skills|summary))\", \n",
    "                             full_resume_text, \n",
    "                             re.IGNORECASE | re.DOTALL)\n",
    "\n",
    "if experience_match:\n",
    "    experience_text = experience_match.group(2).strip()\n",
    "    print(\"[✔] Extracted experience section from raw text.\\n\")\n",
    "else:\n",
    "    print(\"[❌] Could not locate experience section in raw text.\")\n",
    "    experience_text = \"\"\n",
    "\n",
    "print(\"=== Experience Preview ===\")\n",
    "print(experience_text[:1000])\n",
    "\n",
    "# === Step 1: Define GPT-enhancement function ===\n",
    "def enhance_section_with_gpt(section_name, section_text, job_keywords, client=None, model=\"gpt-4\"):\n",
    "    \"\"\"\n",
    "    Uses GPT to rewrite a resume section (summary or skills).\n",
    "    \"\"\"\n",
    "    if client is None:\n",
    "        raise ValueError(\"OpenAI client must be provided.\")\n",
    "\n",
    "    prompt = (\n",
    "        \"You are an expert resume writer.\\n\\n\"\n",
    "        \"Improve the following resume section for clarity, tone, and professionalism.\\n\"\n",
    "        \"Preserve any bullet formatting if it exists.\\n\\n\"\n",
    "        f\"Integrate the following job-relevant keywords naturally and only where appropriate:\\n\"\n",
    "        f\"{', '.join(job_keywords)}\\n\\n\"\n",
    "        f\"Section to improve: {section_name.upper()}\\n\\n\"\n",
    "        f\"```\\n{section_text}\\n```\\n\\n\"\n",
    "        \"Respond only with the improved section text.\"\n",
    "    )\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.7\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "\n",
    "# === Step 2: Sample data ===\n",
    "summary_text = \"\"\"\n",
    "Federal Data Analyst with 4+ years in human capital analytics, data-driven decision-making, and workforce planning. \n",
    "Skilled in SQL, Python, Tableau, and Power BI, with a track record of optimizing HR processes through data analysis, \n",
    "reporting automation, and visualization.\n",
    "\"\"\".strip()\n",
    "\n",
    "skills_text = \"\"\"\n",
    "● Data Analytics & Visualization: SQL · Python · Tableau · Power BI · Advanced Excel · Advanced MS Office Suite  \n",
    "● Human Capital & Workforce Analytics: HR Metrics · Hiring Pipeline Analytics · Employee Retention Analysis\n",
    "\"\"\".strip()\n",
    "\n",
    "job_keywords = [\n",
    "    \"SQL\", \"Python\", \"workforce analytics\", \"reporting automation\", \n",
    "    \"budget forecasting\", \"Power BI\", \"stakeholder communication\"\n",
    "]\n",
    "\n",
    "\n",
    "# === Step 3: Enhance sections using GPT ===\n",
    "real_summary = enhance_section_with_gpt(\"summary\", summary_text, job_keywords, client=client)\n",
    "real_skills = enhance_section_with_gpt(\"skills\", skills_text, job_keywords, client=client)\n",
    "\n",
    "# === Step 4: Output results ===\n",
    "print(\"\\n=== REAL ENHANCED SUMMARY ===\\n\")\n",
    "print(real_summary)\n",
    "\n",
    "print(\"\\n=== REAL ENHANCED SKILLS ===\\n\")\n",
    "print(real_skills)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fallback] No 'education' section found. Trying raw text extraction for education section...\n",
      "[Fallback] No 'skills' section found. Trying raw text extraction for skills section...\n",
      "[Fallback] No 'experience' section found. Trying raw text extraction for experience section...\n",
      "[Fallback] No 'certifications' section found. Trying raw text extraction for certifications section...\n",
      "[Fallback] No 'projects' section found. Trying raw text extraction for projects section...\n",
      "\n",
      "=== Top-Level Resume Sections Extracted ===\n",
      "\n",
      "--- SUMMARY ---\n",
      "Federal Data Analyst with 4+ years in human capital analytics, data-driven decision-making, and workforce planning. Skilled\n",
      "in SQL, Python, Tableau, and Power BI, with a track record of optimizing HR processes through data analysis, reporting\n",
      "automation, and visualization.\n",
      "Professional Skills\n",
      "● Data Analytics & Visualization: SQL · Python · Tableau · Power BI · Advanced Excel · Advanced MS Office Suite\n",
      "● Human Capital & Workforce Analytics: HR Metrics · Hiring Pipeline Analytics · Employee Reten\n",
      "\n",
      "--- OTHER ---\n",
      "workforce planning. Skilled\n",
      "in SQL, Python, Tableau, and Power BI, with a track record of optimizing HR processes through data analysis, reporting\n",
      "automation, and visualization.\n",
      "Professional Skills\n",
      "● Data Analytics & Visualization: SQL · Python · Tableau · Power BI · Advanced Excel · Advanced MS Office Suite\n",
      "● Human Capital & Workforce Analytics: HR Metrics · Hiring Pipeline Analytics · Employee Retention Analysis ·\n",
      "Workforce Planning\n",
      "● Data Management & Integrity: Data Mining · Data Cleaning · \n",
      "\n",
      "--- EDUCATION ---\n",
      "and Certifications\n",
      "Flatiron Data Science Bootcamp\n",
      "Certificate | General Studies\n",
      "• Advanced expertise in Python, SQL, data visualization, machine learning, and feature engineering.\n",
      "• Built and optimized machine learning models for classification, regression, and time series forecasting (ARIMA,\n",
      "XGBoost, LightGBM, Random Forests, Gradient Boosting, Decision Trees) to extract insights from complex\n",
      "datasets.\n",
      "University of Maryland (UMBC) – Baltimore County\n",
      "Bachelor of Arts | Economics\n",
      "HackerRank Inte\n",
      "\n",
      "--- SKILLS ---\n",
      "● Data Analytics & Visualization: SQL · Python · Tableau · Power BI · Advanced Excel · Advanced MS Office Suite\n",
      "● Human Capital & Workforce Analytics: HR Metrics · Hiring Pipeline Analytics · Employee Retention Analysis ·\n",
      "Workforce Planning\n",
      "● Data Management & Integrity: Data Mining · Data Cleaning · Quality Assurance · Database Management · Process\n",
      "Optimization\n",
      "● Reporting & Decision Support: Ad Hoc Reporting · Dashboard Development · Executive Presentations · Stakeholder\n",
      "Communication\n",
      "● Proces\n",
      "\n",
      "--- EXPERIENCE ---\n",
      "Substance Abuse and Mental Health Administration, Department of HHS\n",
      "Budget Analyst Dec '23 - Mar '25\n",
      "· Conducted data mining of critical human capital information across divisions to support strategic decision-making and\n",
      "hiring status evaluations, assessing effectiveness through comprehensive data analysis procedures to enhance workforce\n",
      "planning.\n",
      "· Developed an Excel VBA-based incentive tracking system, integrating engagement analysis and survey design to assess\n",
      "incentive award effectiveness. I\n",
      "\n",
      "--- CERTIFICATIONS ---\n",
      "Flatiron Data Science Bootcamp\n",
      "Certificate | General Studies\n",
      "• Advanced expertise in Python, SQL, data visualization, machine learning, and feature engineering.\n",
      "• Built and optimized machine learning models for classification, regression, and time series forecasting (ARIMA,\n",
      "XGBoost, LightGBM, Random Forests, Gradient Boosting, Decision Trees) to extract insights from complex\n",
      "datasets.\n",
      "University of Maryland (UMBC) – Baltimore County\n",
      "Bachelor of Arts | Economics\n",
      "HackerRank Intermediate SQL Certif\n",
      "\n",
      "--- PROJECTS ---\n",
      "Capstone Project: Substance Abuse Risk Prediction using Machine Learning\n",
      "githubcom/nealiyer88/substance_abuse_risk | Predicting opioid abuse risk using classification models with key behavioral\n",
      "and substance use indicators.\n",
      "· Developed a predictive model using machine learning to assess communication effectiveness based on audience\n",
      "engagement.\n",
      "· Leveraged NLP sentiment analysis to extract insights from stakeholder feedback, improving messaging strategies.\n",
      "· Built interactive Tableau dashboards v\n",
      "\n",
      "=== ENHANCED JOB 1 ===\n",
      "\n",
      "- Leveraged SQL and Python skills to streamline workforce analytics and reporting automation processes.\n",
      "- Utilized Power BI to create interactive dashboards and visually appealing reports for data-driven decision making.\n",
      "- Played a key role in budget forecasting, ensuring efficient allocation of resources and cost-effectiveness.\n",
      "- Enhanced stakeholder communication with regular updates and detailed presentations on project progress and results.\n"
     ]
    }
   ],
   "source": [
    "# === Import parsing functions from experience_splitter.py ===\n",
    "from experience_splitter import split_experience_section, parse_job_entry\n",
    "\n",
    "# === Get the experience section text (from resume parsing pipeline) ===\n",
    "experience_text = parsed_sections.get(\"experience\", \"\")\n",
    "\n",
    "# === Parse experience section into job chunks ===\n",
    "chunks = split_experience_section(experience_text)\n",
    "parsed_jobs = [parse_job_entry(chunk) for chunk in chunks]\n",
    "\n",
    "# === GPT Enhancement Function (Still Inline for Now) ===\n",
    "def enhance_job_entry_with_gpt(job, job_keywords, client=None, model=\"gpt-4\"):\n",
    "    if client is None:\n",
    "        raise ValueError(\"OpenAI client must be provided.\")\n",
    "\n",
    "    context = (\n",
    "        f\"Company: {job['company']}\\n\"\n",
    "        f\"Title: {job['title']}\\n\"\n",
    "        f\"Dates: {job['date_range']}\\n\\n\"\n",
    "        f\"Responsibilities:\\n\" + \"\\n\".join(job['bullets'])\n",
    "    )\n",
    "\n",
    "    prompt = (\n",
    "        \"You are a professional resume writer.\\n\\n\"\n",
    "        \"Improve the job description below by:\\n\"\n",
    "        \"- Enhancing clarity, conciseness, and tone\\n\"\n",
    "        \"- Preserving bullet formatting\\n\"\n",
    "        \"- Integrating the following job keywords naturally (only where relevant):\\n\"\n",
    "        f\"{', '.join(job_keywords)}\\n\\n\"\n",
    "        \"Rewrite this job experience:\\n\\n\"\n",
    "        f\"```\\n{context}\\n```\\n\\n\"\n",
    "        \"Respond with just the improved bullet points, in bullet format.\"\n",
    "    )\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.7,\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "\n",
    "# === Enhance First Job for Testing ===\n",
    "enhanced_job_1 = enhance_job_entry_with_gpt(parsed_jobs[0], job_keywords, client=client)\n",
    "\n",
    "print(\"\\n=== ENHANCED JOB 1 ===\\n\")\n",
    "print(enhanced_job_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[✔] Extracted experience section from raw text.\n",
      "\n",
      "\n",
      "=== FINAL ENHANCED EXPERIENCE SECTION ===\n",
      "\n",
      "Company: Substance Abuse and Mental Health Administration, Department of HHS\n",
      "Title: Budget Analyst\n",
      "Dates: Dec '23 - Mar '25\n",
      "\n",
      "- Leveraged SQL and Python to mine human capital data across divisions, enhancing strategic decision-making and hiring evaluations, while improving workforce analytics.\n",
      "- Created an Excel VBA-based incentive tracking system with automated validation checks, bolstering data accuracy by 85% and enriching communication-engagement insights.\n",
      "- Developed a real-time payroll tracking system using Python and SQL, integrating multiple fund sources and lines of accounting, reducing reconciliation time by ~2 hours/month and enhancing payroll forecasting accuracy.\n",
      "- Optimized SharePoint-based data management processes for financial reporting, improving workflow automation and document version control.\n",
      "- Led financial forecasting and variance analysis for a $165M payroll budget, resulting in actionable full-time equivalent adjustments and accurate full-year payroll projections.\n",
      "- Designed Power BI dashboards for real-time insights into budget utilization, payroll trends, and workforce analytics, facilitating data-driven decision-making.\n",
      "- Conducted cross-functional workshops with stakeholders, optimizing decision pathways and reducing budget approval processing time by 30%.\n",
      "- Collaborated with data science teams to analyze user interactions and refine AI algorithms, reducing budget forecasting errors by 15% and improving financial planning accuracy.\n",
      "- Managed human capital reporting and workforce analytics adherence to federal regulations and data privacy laws, ensuring timely and accurate reporting.\n",
      "\n",
      "Company: CRI – Department of the Interior\n",
      "Title: Budget Analyst\n",
      "Dates: Mar '21 - Dec '23\n",
      "\n",
      "- Orchestrated data quality enhancement strategies, boosting financial data accuracy by 20% through trend analysis and process enhancements across reporting platforms.\n",
      "- Facilitated cross-functional collaboration between IT and Finance departments, optimizing financial database integration and analytics workflows.\n",
      "- Leveraged Python and SQL to engineer workflow automation solutions, streamlining reporting processes and decreasing manual workload by 15%.\n",
      "- Instituted standardized annotation guidelines for financial reporting, promoting consistency in data analysis and AI training datasets.\n",
      "- Utilized Power BI for budget forecasting and workforce analytics, improving stakeholder communication and reporting automation efficiency.\n",
      "\n",
      "Company: Cresa\n",
      "Title: Accounting Analyst\n",
      "Dates: Dec '20 - Mar '21\n",
      "\n",
      "- Leveraged SQL and Python skills to conduct data analysis on expense trends and revenue forecasts, enhancing executive decision-making with precise insights.\n",
      "- Augmented financial accuracy by reconciling data, successfully streamlining reporting on budget allocations and marketing expenditures.\n",
      "- Utilized Power BI in automating reporting process, reducing time spent on manual tasks and increasing productivity.\n",
      "- Contributed to workforce analytics by providing meticulous budget forecasting, aiding in strategic resource allocation.\n",
      "- Enhanced stakeholder communication by presenting complex financial data in a simplified and structured manner, facilitating informed business decisions.\n",
      "\n",
      "Company: FrontStream\n",
      "Title: Fund Accountant\n",
      "Dates: Aug '18 - Sep '20\n",
      "\n",
      "- Streamlined financial reconciliation process through SQL and VBA automation, saving over 250 hours annually.\n",
      "- Oversaw a portfolio of nonprofit donations, leveraging data-driven decisions for optimal fund distribution.\n",
      "- Created real-time financial tracking dashboards using Power BI, enhancing transparency for key stakeholders.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pdfplumber\n",
    "from experience_splitter import split_experience_section, parse_job_entry\n",
    "\n",
    "# === Load PDF ===\n",
    "pdf_path = \"docs/sample_resume.pdf\"\n",
    "if not os.path.exists(pdf_path):\n",
    "    raise FileNotFoundError(f\"❌ Resume file not found at: {pdf_path}\")\n",
    "\n",
    "with pdfplumber.open(pdf_path) as pdf:\n",
    "    full_resume_text = \"\\n\".join(page.extract_text() for page in pdf.pages if page.extract_text())\n",
    "\n",
    "# === Extract experience section using fallback ===\n",
    "experience_match = re.search(\n",
    "    r\"(experience|work history|employment|professional experience)(.*?)\"\n",
    "    r\"((education|projects|certifications|skills|summary))\",\n",
    "    full_resume_text,\n",
    "    re.IGNORECASE | re.DOTALL,\n",
    ")\n",
    "\n",
    "if experience_match:\n",
    "    experience_text = experience_match.group(2).strip()\n",
    "    print(\"[✔] Extracted experience section from raw text.\\n\")\n",
    "else:\n",
    "    print(\"[❌] Could not locate experience section in raw text.\")\n",
    "    experience_text = \"\"\n",
    "\n",
    "# === Parse into job chunks ===\n",
    "chunks = split_experience_section(experience_text)\n",
    "parsed_jobs = [parse_job_entry(chunk) for chunk in chunks]\n",
    "\n",
    "# ✅ Remove any placeholder/empty job blocks\n",
    "parsed_jobs = [j for j in parsed_jobs if j[\"company\"] and j[\"title\"]]\n",
    "\n",
    "# === GPT Enhancement per job ===\n",
    "def enhance_job_entry_with_gpt(job, job_keywords, client=None, model=\"gpt-4\"):\n",
    "    if client is None:\n",
    "        raise ValueError(\"OpenAI client must be provided.\")\n",
    "\n",
    "    context = (\n",
    "        f\"Company: {job['company']}\\n\"\n",
    "        f\"Title: {job['title']}\\n\"\n",
    "        f\"Dates: {job['date_range']}\\n\\n\"\n",
    "        f\"Responsibilities:\\n\" + \"\\n\".join(job['bullets'])\n",
    "    )\n",
    "\n",
    "    prompt = (\n",
    "        \"You are a professional resume writer.\\n\\n\"\n",
    "        \"Improve the job description below by:\\n\"\n",
    "        \"- Enhancing clarity, conciseness, and tone\\n\"\n",
    "        \"- Limiting to 3–5 strong, high-impact bullets per job\\n\"\n",
    "        \"- Avoiding repetitive phrasing (e.g., do not overuse 'leveraged', 'developed', etc.)\\n\"\n",
    "        \"- Preserving bullet formatting\\n\"\n",
    "        \"- Integrating the following job keywords naturally (only where relevant):\\n\"\n",
    "        f\"{', '.join(job_keywords)}\\n\"\n",
    "        \"- Ensuring each bullet clearly answers 'So what?' by showing impact, outcomes, or business value\\n\"\n",
    "        \"- Quantifying results where possible (e.g., time saved, accuracy improved, % growth)\\n\"\n",
    "        \"- Do not invent or exaggerate accomplishments. Only reword what is already in the resume.\\n\\n\"\n",
    "        \"Rewrite this job experience:\\n\\n\"\n",
    "        f\"```\\n{context}\\n```\\n\\n\"\n",
    "        \"Respond with just the improved bullet points, in bullet format.\"\n",
    "    )\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.7,\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "# === Enhance All Jobs ===\n",
    "enhanced_jobs = []\n",
    "for job in parsed_jobs:\n",
    "    enhanced_bullets = enhance_job_entry_with_gpt(job, job_keywords, client=client)\n",
    "    enhanced_jobs.append({\n",
    "        \"company\": job[\"company\"],\n",
    "        \"title\": job[\"title\"],\n",
    "        \"date_range\": job[\"date_range\"],\n",
    "        \"bullets\": enhanced_bullets\n",
    "    })\n",
    "\n",
    "# === Format the final output ===\n",
    "def format_enhanced_experience(enhanced_jobs):\n",
    "    formatted = []\n",
    "    for job in enhanced_jobs:\n",
    "        block = f\"\"\"Company: {job['company']}\n",
    "Title: {job['title']}\n",
    "Dates: {job['date_range']}\n",
    "\n",
    "{job['bullets']}\n",
    "\"\"\"\n",
    "        formatted.append(block.strip())\n",
    "    return \"\\n\\n\".join(formatted)\n",
    "\n",
    "# === Display Results ===\n",
    "full_enhanced_experience = format_enhanced_experience(enhanced_jobs)\n",
    "\n",
    "print(\"\\n=== FINAL ENHANCED EXPERIENCE SECTION ===\\n\")\n",
    "print(full_enhanced_experience)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fallback] No 'education' section found. Trying raw text extraction for education section...\n",
      "[Fallback] No 'skills' section found. Trying raw text extraction for skills section...\n",
      "[Fallback] No 'experience' section found. Trying raw text extraction for experience section...\n",
      "[Fallback] No 'certifications' section found. Trying raw text extraction for certifications section...\n",
      "[Fallback] No 'projects' section found. Trying raw text extraction for projects section...\n",
      "=== Extracted Sections ===\n",
      "- summary\n",
      "- education\n",
      "- skills\n",
      "- experience\n",
      "- certifications\n",
      "- projects\n",
      "- other\n",
      "\n",
      "=== Experience Section ===\n",
      "Substance Abuse and Mental Health Administration, Department of HHS\n",
      "Budget Analyst\n",
      "Dec '23 - Mar '25\n",
      "·  Conducted data mining of critical human capital information across divisions to support strategic decision-making and\n",
      "hiring status evaluations, assessing effectiveness through comprehensive data analysis procedures to enhance workforce\n",
      "planning.\n",
      "·  Developed an Excel VBA-based incentive tracking system, integrating engagement analysis and survey design to assess\n",
      "incentive award effectiveness. Implemented automated validation checks and dynamic data processing workflows,\n",
      "increasing data accuracy by 85% and enhancing communication-engagement data insights for decision-making.\n",
      "·  Engineered a real-time Python-based payroll tracking system, integrating 10+ fund sources and 25 Lines of Accounting,\n",
      "leveraging SQL for data extraction and pandas for analysis, reducing reconciliation time by ~2 hours/month and\n",
      "improving payroll forecasting accuracy.\n",
      "·  Designed and optimized SharePoint-based\n",
      "✅ Experience section exists: True\n",
      "📝 Raw experience text length: 4935\n",
      "\n",
      "--- Preview ---\n",
      " Substance Abuse and Mental Health Administration, Department of HHS\n",
      "Budget Analyst\n",
      "Dec '23 - Mar '25\n",
      "·  Conducted data mining of critical human capital information across divisions to support strategic decision-making and\n",
      "hiring status evaluations, assessing effectiveness through comprehensive data analysis procedures to enhance workforce\n",
      "planning.\n",
      "·  Developed an Excel VBA-based incentive tracking system, integrating engagement analysis and survey design to assess\n",
      "incentive award effectiveness.\n"
     ]
    }
   ],
   "source": [
    "from parsing_module import extract_text_pdfminer, split_resume_into_sections\n",
    "\n",
    "# Point to the same resume you used previously\n",
    "pdf_path = \"docs/sample_resume.pdf\"\n",
    "\n",
    "# Extract full resume text\n",
    "resume_text = extract_text_pdfminer(pdf_path)\n",
    "\n",
    "# Run the updated section splitter\n",
    "parsed_sections = split_resume_into_sections(resume_text, pdf_path=pdf_path)\n",
    "\n",
    "# Print all section keys\n",
    "print(\"=== Extracted Sections ===\")\n",
    "for section in parsed_sections:\n",
    "    print(\"-\", section)\n",
    "\n",
    "# Specifically print experience section\n",
    "print(\"\\n=== Experience Section ===\")\n",
    "print(parsed_sections.get(\"experience\", \"[Not Found]\")[:1000])  # Preview first 1000 chars\n",
    "print(\"✅ Experience section exists:\", \"experience\" in parsed_sections)\n",
    "print(\"📝 Raw experience text length:\", len(parsed_sections.get(\"experience\", \"\")))\n",
    "print(\"\\n--- Preview ---\\n\", parsed_sections.get(\"experience\", \"\")[:500])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fallback] No 'education' section found. Trying raw text extraction for education section...\n",
      "[Fallback] No 'skills' section found. Trying raw text extraction for skills section...\n",
      "[Fallback] No 'experience' section found. Trying raw text extraction for experience section...\n",
      "[Fallback] No 'certifications' section found. Trying raw text extraction for certifications section...\n",
      "[Fallback] No 'projects' section found. Trying raw text extraction for projects section...\n",
      "Company: Substance Abuse and Mental Health Administration, Department of HHS\n",
      "Title: Budget Analyst\n",
      "Dates: Dec '23 - Mar '25\n",
      "\n",
      "- Leveraged SQL and Python to engineer a real-time payroll tracking system, integrating multiple fund sources and lines of accounting, resulting in a 2-hour/month reduction in reconciliation time and improved payroll forecasting accuracy.\n",
      "- Implemented an Excel VBA-based incentive tracking system with automated validation checks, enhancing data accuracy by 85% and providing valuable insights for strategic decision-making.\n",
      "- Conducted efficient financial forecasting and variance analysis for a $165M payroll budget, leading to data-driven FTE adjustments and full-year payroll projections, optimizing budget allocation.\n",
      "- Utilized Power BI to create dynamic dashboards, delivering real-time insights into budget utilization, payroll trends, and workforce analytics to support data-driven decision making.\n",
      "- Facilitated cross-functional workshops to gather insights, resulting in a 30% reduction in processing time for budget approvals and improved optimization of decision pathways.\n",
      "- Collaborated with data science teams to optimize AI algorithms, reducing budget forecasting errors by 15% and enhancing overall accuracy in financial planning.\n",
      "- Ensured full compliance with federal regulations and data privacy laws in all reporting processes, managing deadlines effectively to ensure timely and accurate reporting.\n",
      "\n",
      "Company: CRI – Department of the Interior\n",
      "Title: Budget Analyst\n",
      "Dates: Mar '21 - Dec '23\n",
      "\n",
      "- Spearheaded data quality improvement strategies, amplifying financial data precision by 20% through pattern and trend analysis for continuous process enhancement.\n",
      "- Fostered cross-departmental collaboration between IT and Finance teams, enhancing database integration and analytics workflows for improved financial management.\n",
      "- Implemented workflow automation solutions using Python and SQL, streamlining reporting processes and reducing manual workload by 15%.\n",
      "- Established standardized annotation guidelines for financial reporting, ensuring uniformity in data analysis and AI training datasets.\n",
      "- Leveraged Power BI for budget forecasting, enabling accurate financial planning and strategic decision-making.\n",
      "\n",
      "Company: Cresa\n",
      "Title: Accounting Analyst\n",
      "Dates: Dec '20 - Mar '21\n",
      "\n",
      "- Streamlined executive decision-making process by analyzing expense trends and revenue forecasts, using SQL and Python to enhance accuracy of projections.\n",
      "- Improved budget planning efficiency by reconciling financial data and providing structured Power BI reports on budget allocations, reducing discrepancies by 20%.\n",
      "- Optimized marketing expenditure tracking by providing detailed structured reports, contributing to a 15% decrease in unnecessary spending.\n",
      "\n",
      "Company: FrontStream\n",
      "Title: Fund Accountant\n",
      "Dates: Aug '18 - Sep '20\n",
      "\n",
      "Company: FrontStream\n",
      "Title: Fund Accountant\n",
      "Dates: Aug '18 - Sep '20\n",
      "\n",
      "Key Achievements:\n",
      "• Streamlined financial reconciliation process using SQL and VBA, resulting in an annual reduction of manual workload by over 250 hours.\n",
      "• Steered data-driven decision-making for fund distribution, effectively managing a portfolio of nonprofit donations.\n",
      "• Constructed real-time financial tracking dashboards through Power BI, enhancing stakeholder transparency.\n",
      "\n",
      "Education and Certifications:\n",
      "• Flatiron Data Science Bootcamp Certificate | General Studies: Gained advanced expertise in Python, SQL, data visualization, machine learning, and feature engineering.\n",
      "• Developed machine learning models for classification, regression, and time series forecasting to extract insights from complex data.\n",
      "\n",
      "Projects:\n",
      "• Capstone Project: Substance Abuse Risk Prediction using Machine Learning: Built a predictive model using machine learning to evaluate communication effectiveness by audience engagement.\n",
      "• Utilized NLP sentiment analysis to derive insights from stakeholder feedback, refining messaging strategies.\n",
      "• Created interactive Tableau dashboards to visualize campaign performance and refine communication strategies.\n",
      "• Zillow Real Estate Price Forecasting w/ Time Series: Applied ARIMA modeling and time series forecasting for predicting real estate price trends, enhancing data-driven investment decisions.\n"
     ]
    }
   ],
   "source": [
    "from llm_enhancer import enhance_resume_experience\n",
    "\n",
    "pdf_path = \"docs/sample_resume.pdf\"\n",
    "job_keywords = [\"SQL\", \"Python\", \"Power BI\", \"budget forecasting\"]\n",
    "output = enhance_resume_experience(pdf_path, job_keywords)\n",
    "print(output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
